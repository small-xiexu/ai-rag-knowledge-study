# AI 基础知识学习指南 🤖

> 面向零基础用户：从概念到实践，掌握大模型、向量、RAG 等 AI 核心知识

---

## 📋 学习目标

完成本文档后，你将理解：
- ✅ 大语言模型（LLM）是什么，如何工作
- ✅ 向量和 Embedding 的概念与作用
- ✅ 向量数据库（pgvector）为什么重要
- ✅ RAG（检索增强生成）的原理与价值
- ✅ Ollama 如何让你在本地运行 AI 模型

---

## 🧠 第一章：大语言模型（LLM）

### 什么是大语言模型？

**大语言模型 (Large Language Model, LLM)** 是一种 AI 程序，经过海量文本训练，能够理解和生成人类语言。

```
输入：你好，请介绍一下自己
  ↓
┌─────────────────────────────────┐
│       大语言模型 (LLM)           │
│  参数量：几十亿到几千亿个数字     │
│  训练数据：互联网上的海量文本     │
└─────────────────────────────────┘
  ↓
输出：你好！我是一个 AI 助手，可以帮助你...
```

### 常见的大语言模型

| 模型 | 开发者 | 特点 |
|------|--------|------|
| GPT-4 | OpenAI | 商用最强，需付费 API |
| Claude | Anthropic | 长文本处理强，安全性高 |
| Llama | Meta | **开源**，可本地运行 |
| Qwen (通义千问) | 阿里 | **开源**，中文能力强 |
| DeepSeek | 深度求索 | **开源**，推理能力强 |

### 模型的"参数"是什么？

参数就是模型"学到"的知识，用数字表示：

```
模型越大（参数越多）→ 能力越强 → 消耗资源越多

示例：
- Qwen2.5:0.5B  = 5 亿参数，需要 ~2GB 内存
- Qwen2.5:7B   = 70 亿参数，需要 ~8GB 内存  
- Qwen2.5:72B  = 720 亿参数，需要 ~80GB 内存
```

### 模型的局限性（重要！）

LLM 很强大，但有几个关键的局限。**理解这些局限，是理解 RAG 技术价值的关键**。

#### 局限一：知识截止 ⏰

**问题**：LLM 的知识来自训练数据，而训练有截止时间。

```
打个比方：

假设你在 2024 年 1 月买了一本百科全书
- 这本书不知道 2024 年 3 月发生的事
- 无论你怎么问，书里都没有这些内容
- 要获取新知识，只能买新版的书（重新训练模型）

LLM 也是一样：
- GPT-4 的训练数据截止到某个时间点
- 问它"2024年12月的新闻"，它会说"不知道"
- 重新训练模型成本极高（几百万美元 + 几个月时间）
```

**实际例子**：
```
用户：最新的 Spring Boot 版本是多少？
LLM：根据我的知识，最新版本是 3.2.x... ← 可能已经过时了！
```

#### 局限二：无法访问私有数据 🔒

**问题**：LLM 只知道互联网上公开的信息。

```
打个比方：

请一个外人回答关于你公司的问题：
- "我们公司的年假政策是什么？" → 不知道
- "这个项目的技术架构是什么？" → 不知道
- "客户张三的订单状态？" → 不知道

外人不是不够聪明，而是根本没看过你公司的资料！
LLM 也是一样——它再聪明，也无法回答它没见过的内容。
```

**实际例子**：
```
用户：我们公司报销流程是什么？
LLM：抱歉，我无法访问贵公司的内部规定... ← 它真的不知道！
```

#### 其他局限

| 局限 | 说明 |
|------|------|
| **幻觉** | 可能编造看似合理但错误的内容 |
| **无法精确计算** | 数学计算可能出错 |

---

### RAG 如何解决这些问题？

**简单来说**：RAG 让 AI 从"闭卷考试"变成"开卷考试"。

#### 解决知识截止 → 随时更新知识库

```
┌─────────────────────────────────────────────────────────────┐
│                      传统 LLM                                │
├─────────────────────────────────────────────────────────────┤
│  用户：Spring Boot 最新版本是多少？                          │
│  模型：（只能靠训练时的记忆）3.2.x...                         │
│                                                             │
│  ❌ 问题：训练后发布的新版本，模型不知道                       │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│                      RAG 增强                                │
├─────────────────────────────────────────────────────────────┤
│  用户：Spring Boot 最新版本是多少？                          │
│                                                             │
│  Step 1: 从知识库检索最新信息                                │
│         → 找到："Spring Boot 3.4.0 于 2024.11 发布"          │
│                                                             │
│  Step 2: 把检索结果给 LLM                                   │
│         → "根据以下资料回答：[检索结果] 问题：最新版本？"      │
│                                                             │
│  Step 3: LLM 基于资料回答                                   │
│         → "最新版本是 3.4.0"                                │
│                                                             │
│  ✅ 只要知识库里有最新信息，AI 就能回答！                      │
└─────────────────────────────────────────────────────────────┘
```

#### 解决私有数据 → 上传到知识库

```
┌─────────────────────────────────────────────────────────────┐
│                      传统 LLM                                │
├─────────────────────────────────────────────────────────────┤
│  用户：公司的年假政策是什么？                                 │
│  模型：抱歉，我无法访问贵公司的内部信息...                     │
│                                                             │
│  ❌ 模型训练时没见过你公司的文档                               │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│                      RAG 增强                                │
├─────────────────────────────────────────────────────────────┤
│  【准备工作】把公司规章制度上传到知识库                        │
│                                                             │
│  用户：公司的年假政策是什么？                                 │
│                                                             │
│  Step 1: 从知识库检索                                       │
│         → 找到"员工手册.pdf"中的年假章节                     │
│                                                             │
│  Step 2: 把内容给 LLM                                       │
│         → "根据以下公司规定回答：[年假章节内容]..."           │
│                                                             │
│  Step 3: LLM 基于资料回答                                   │
│         → "根据公司规定，员工入职满一年可享受5天年假..."       │
│                                                             │
│  ✅ 把私有文档导入知识库，AI 就能基于它回答！                  │
└─────────────────────────────────────────────────────────────┘
```

#### 一个形象的比喻 📚

```
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│   传统 LLM = 只靠脑子里的记忆答题                            │
│   - 可能记错（幻觉）                                         │
│   - 可能过时（知识截止）                                     │
│   - 没学过的就不会（私有数据）                               │
│                                                             │
│   RAG = 开卷考试，可以翻书查资料                             │
│   - 书里有最新内容（解决知识截止）                            │
│   - 可以带自己的笔记（解决私有数据）                          │
│   - 答案更有依据（减少幻觉）                                 │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

> 💡 **本质**：RAG 不是让 AI 更聪明，而是给 AI 一个可以随时更新的"参考资料库"。

---

## 📐 第二章：向量与 Embedding

> 这一章是理解 RAG 的关键！请耐心阅读。

### 先问一个问题：计算机如何理解文字？

**答案是：它不理解。** 计算机只认识数字（0 和 1）。

```
人类看到：  "今天天气真好"  → 理解意思 → 可以回应
计算机看到："今天天气真好"  → 一串字符编码 → 不理解含义
```

**那怎么让计算机"理解"文字呢？**

把文字转成数字！而且这些数字要能**代表文字的含义**。

---

### 什么是向量？

**向量 (Vector)** 就是"一组数字"，在 AI 领域用来表示某个事物的"含义"。

```
"苹果" → [0.23, -0.45, 0.67, 0.12, ..., 0.89]
           ↑ 这一组数字就是"苹果"的向量
           通常有 768 或 1536 个数字
```

**为什么一个词需要这么多数字？**

因为每个数字代表一个"特征维度"。比如（这只是简化示例）：

```
假设用 5 个数字表示一个词：

          [水果程度, 甜度, 颜色偏红, 体积, 是食物]
          
"苹果" → [  0.9,    0.7,   0.8,    0.3,   1.0  ]
"橘子" → [  0.9,    0.6,   0.6,    0.3,   1.0  ]  ← 和苹果很像！
"汽车" → [  0.0,    0.0,   0.1,    0.9,   0.0  ]  ← 和苹果完全不同
```

**关键理解**：
- 含义相近的词 → 向量数字相近
- 含义不同的词 → 向量数字差异大

---

### 什么是 Embedding？

**Embedding（嵌入）** 是把文本转换成向量的**过程**。

```
┌─────────────────────────────────────────────────────────────┐
│                     Embedding 过程                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   输入：文本                                                 │
│   "我喜欢吃苹果"                                             │
│         ↓                                                   │
│   ┌─────────────────────────────────────┐                   │
│   │         Embedding 模型               │                   │
│   │    (如 nomic-embed-text)            │                   │
│   │                                     │                   │
│   │    这是一个经过训练的神经网络         │                   │
│   │    它"学会了"如何把文字转成向量       │                   │
│   └─────────────────────────────────────┘                   │
│         ↓                                                   │
│   输出：向量                                                 │
│   [0.12, -0.34, 0.56, 0.78, 0.23, ..., 0.45]               │
│                                                             │
│   这个向量代表了"我喜欢吃苹果"的**语义含义**                   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

### Embedding 模型是怎么训练出来的？

**核心思想**：大量阅读文本，学习词语之间的关系。

```
训练过程（简化说明）：

1. 给模型喂海量文本
   "苹果是一种水果"
   "橘子也是一种水果"
   "汽车是交通工具"
   ...（几十亿句话）

2. 模型发现规律
   "苹果"和"橘子"经常出现在相似的句子里
   → 它们的向量应该相近
   
   "苹果"和"汽车"很少一起出现
   → 它们的向量应该相距远

3. 训练完成后
   模型学会了：
   - 把相似含义的词转成相近的向量
   - 把不同含义的词转成相距远的向量
```

---

### 向量相似度：如何比较两段文字是否相似？

把两段文字都转成向量，然后**计算向量之间的距离**。

```
用户问题："推荐一些好吃的水果"
                ↓ Embedding
问题向量：[0.32, -0.45, 0.67, ...]

知识库中的文档：
┌──────────────────────────────────────────────────────────┐
│ 文档1："苹果富含维生素"    → 向量A [0.30, -0.42, 0.65, ...]│
│                            与问题向量距离: 0.05（很近）✓  │
├──────────────────────────────────────────────────────────┤
│ 文档2："汽车保养指南"      → 向量B [-0.56, 0.89, -0.12, ...]│
│                            与问题向量距离: 1.82（很远）   │
├──────────────────────────────────────────────────────────┤
│ 文档3："橘子的营养价值"    → 向量C [0.28, -0.40, 0.63, ...]│
│                            与问题向量距离: 0.08（较近）✓  │
└──────────────────────────────────────────────────────────┘

结论：文档1 和 文档3 与问题最相关！
```

这就是**语义搜索**的原理！

---

### 为什么这比关键词搜索更好？

```
传统关键词搜索：
用户搜索："水果" 
→ 只能找到包含"水果"这两个字的文档
→ 没写"水果"的相关内容找不到

用户搜索："我想买点健康食品"
→ 文档里没有"健康食品"四个字？找不到！

────────────────────────────────────────────────────────────

向量语义搜索：
用户搜索："我想买点健康食品"
→ 转成向量
→ 找到向量相近的文档
→ 即使文档写的是"新鲜水果推荐"也能匹配上！
   因为它们的**语义含义**相近
```

---

### 动手理解：调用 Embedding 接口

```bash
# 用 Ollama 调用 Embedding 接口
curl http://localhost:11434/api/embeddings -d '{
  "model": "nomic-embed-text",
  "prompt": "苹果是一种水果"
}'

# 返回结果（简化）：
{
  "embedding": [0.123, -0.456, 0.789, 0.234, ...]
  # ↑ 这就是"苹果是一种水果"的向量表示
  # 通常有 768 个数字
}
```

你可以试试：
1. 输入 "苹果是一种水果"，得到向量 A
2. 输入 "橘子也是水果"，得到向量 B
3. 输入 "汽车需要加油"，得到向量 C

然后你会发现：A 和 B 的数字很接近，C 的数字差异很大！

---

### 常用 Embedding 模型

| 模型 | 开发者 | 向量维度 | 特点 |
|------|--------|----------|------|
| text-embedding-ada-002 | OpenAI | 1536 | 商用，效果好 |
| nomic-embed-text | Nomic AI | 768 | **开源**，可本地运行 |
| bge-large-zh | 智源 | 1024 | **开源**，中文优化 |
| m3e-base | Moka AI | 768 | **开源**，中英双语 |

> 💡 **向量维度**：向量包含多少个数字。维度越高，能表达的含义越丰富，但存储和计算成本也越高。

### Embedding 模型与其他 AI 模型的区别

不同类型的 AI 模型有不同的用途，别搞混了：

| 模型类型 | 输入 | 输出 | 主要用途 |
|----------|------|------|----------|
| **Embedding 模型** | 文本 | **向量**（一组数字） | 语义搜索、相似度计算 |
| 对话模型 (LLM) | 文本 | 文本（回复） | 聊天、问答、写作 |
| 图像生成模型 | 文本 | 图片 | AI 绘画 |
| 语音识别模型 | 语音 | 文本 | 语音转文字 |

**关键区别**：
- **Embedding 模型**：输出的是数字，用于"理解"和"搜索"
- **对话模型**：输出的是文字，用于"生成"和"回答"

```
同样输入 "苹果是什么"：

Embedding 模型 → [0.23, -0.45, 0.67, ...]  ← 向量，人看不懂
对话模型 (LLM) → "苹果是一种常见的水果..." ← 文字，人能看懂
```

> 💡 在 RAG 中，**两种模型都要用到**：Embedding 模型负责"检索"，对话模型负责"回答"。

---

### 本章小结

```
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  Embedding 解决了一个核心问题：                              │
│                                                             │
│  让计算机"理解"文字的含义                                    │
│                                                             │
│  文本 ──Embedding模型──▶ 向量（一组数字）                    │
│                                                             │
│  含义相近的文本 → 向量相近 → 可以通过计算距离找到相似内容      │
│                                                             │
│  这就是 RAG 中"检索相关文档"的底层原理！                      │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

### 完整流程：从用户提问到 AI 回答

现在你已经理解了 Embedding，让我们看看**完整的 RAG 问答流程**：

```
┌─────────────────────────────────────────────────────────────────┐
│                 RAG 完整问答流程（8 个步骤）                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   👤 用户提问                                                    │
│   "公司的年假政策是什么？"                                        │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 1: 把问题转成向量                  │                     │
│   │ "公司的年假政策是什么？"                 │                     │
│   │      ↓ Embedding 模型                  │                     │
│   │ 问题向量: [0.23, -0.45, 0.67, ...]     │                     │
│   └───────────────────────────────────────┘                     │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 2: 在向量数据库中搜索相似内容       │                     │
│   │                                       │                     │
│   │ 比较问题向量与数据库中所有文档向量的距离  │                     │
│   │ 找出最相似的 Top 3 个文档块             │                     │
│   └───────────────────────────────────────┘                     │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 3: 获取相似文档的原文              │                     │
│   │                                       │                     │
│   │ 文档1: "员工入职满一年可享受5天年假..."  │                     │
│   │ 文档2: "年假需提前3天向主管申请..."     │                     │
│   │ 文档3: "未休年假可折算工资..."          │                     │
│   └───────────────────────────────────────┘                     │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 4: 组装 Prompt（提示词）           │                     │
│   │                                       │                     │
│   │ "请根据以下资料回答用户的问题：          │                     │
│   │                                       │                     │
│   │  【参考资料】                           │                     │
│   │  - 员工入职满一年可享受5天年假...       │                     │
│   │  - 年假需提前3天向主管申请...           │                     │
│   │  - 未休年假可折算工资...                │                     │
│   │                                       │                     │
│   │  【用户问题】                           │                     │
│   │  公司的年假政策是什么？"                 │                     │
│   └───────────────────────────────────────┘                     │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 5: 发送给对话模型 (LLM)            │                     │
│   │                                       │                     │
│   │ Prompt ──────▶ GPT-4 / Qwen / Ollama  │                     │
│   └───────────────────────────────────────┘                     │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 6: LLM 阅读资料并生成回答          │                     │
│   │                                       │                     │
│   │ LLM 会根据 Step 4 提供的参考资料        │                     │
│   │ 组织语言，生成通顺的回答                │                     │
│   └───────────────────────────────────────┘                     │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 7: 流式返回答案                   │                     │
│   │                                       │                     │
│   │ "根据公司规定：                         │                     │
│   │  1. 员工入职满一年可享受5天年假         │                     │
│   │  2. 请假需提前3天向主管申请             │                     │
│   │  3. 年底未休完的年假可折算工资"         │                     │
│   └───────────────────────────────────────┘                     │
│           │                                                     │
│           ▼                                                     │
│   👤 用户看到答案                                                │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**简化版流程图**：

```
用户提问 ──▶ Embedding ──▶ 向量搜索 ──▶ 取出相关文档 ──▶ 组装Prompt ──▶ LLM ──▶ 回答
   │           │            │              │              │         │       │
   │        转向量        找相似         拿原文          拼提示词    生成    展示
   │                                                                        │
   └────────────────────────────────────────────────────────────────────────┘
```

**两种模型的分工**：

| 步骤 | 使用的模型 | 作用 |
|------|------------|------|
| Step 1 | **Embedding 模型** | 把问题转成向量 |
| Step 2-3 | 向量数据库 | 找相似并取出原文 |
| Step 5-6 | **对话模型 (LLM)** | 阅读资料并生成回答 |

> 💡 **核心理解**：Embedding 负责"找资料"，LLM 负责"写答案"，两者配合完成 RAG。

---

## 🗃️ 第三章：向量数据库

### 为什么需要向量数据库？

传统数据库擅长**精确匹配**：
```sql
SELECT * FROM products WHERE name = '苹果'  -- 精确查找
```

但无法做**语义搜索**：
```sql
-- 传统数据库做不到：
-- "找到与'我想买水果'含义相近的商品"
```

**向量数据库**通过比较向量相似度，实现语义搜索：

```
用户查询: "推荐一些健康食品"
           ↓ Embedding
        查询向量
           ↓ 相似度搜索
┌──────────────────────────────────────┐
│           向量数据库                  │
│  [苹果向量]     相似度: 0.82 ✓       │
│  [薯片向量]     相似度: 0.35         │
│  [沙拉向量]     相似度: 0.88 ✓       │
│  [手机向量]     相似度: 0.12         │
└──────────────────────────────────────┘
           ↓
返回: 苹果、沙拉 (语义最相关的结果)
```

### PostgreSQL + pgvector

**pgvector** 是 PostgreSQL 的向量扩展，让传统数据库也能存储和搜索向量。

```sql
-- 创建带向量列的表
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT,
    embedding VECTOR(768)  -- 768 维向量
);

-- 插入数据（包含向量）
INSERT INTO documents (content, embedding) 
VALUES ('苹果是一种水果', '[0.12, -0.34, 0.56, ...]');

-- 相似度搜索（找到最相关的 5 条）
SELECT content, embedding <=> '[0.11, -0.32, 0.55, ...]' AS distance
FROM documents
ORDER BY distance
LIMIT 5;
```

**`<=>` 操作符**：计算两个向量的距离，值越小越相似。

### 为什么选择 pgvector？

| 特点 | 说明 |
|------|------|
| **集成性** | 复用现有 PostgreSQL，不需要额外数据库 |
| **SQL 兼容** | 可以结合传统查询条件筛选 |
| **成熟稳定** | 基于 PostgreSQL，生态完善 |
| **开源免费** | 无商业授权费用 |

---

### 文档如何存入向量数据库？（存储流程）

当你上传一份文档（如 PDF、Word）到系统时，会经历以下过程：

```
┌─────────────────────────────────────────────────────────────────┐
│                    文档存储完整流程（6 个步骤）                    │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   📄 你上传的文档                                                │
│   "员工手册.pdf"（100页）                                        │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 1: 读取文档内容                   │                     │
│   │                                       │                     │
│   │ 把 PDF/Word/TXT 转成纯文本             │                     │
│   │ "第一章 公司简介...第二章 员工守则..."  │                     │
│   └───────────────────────────────────────┘                     │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 2: 分割成小块 (Chunking)          │                     │
│   │                                       │                     │
│   │ 为什么要分割？                         │                     │
│   │ - 整篇文档太长，向量无法精确表示         │                     │
│   │ - 小块更容易匹配用户的具体问题          │                     │
│   │                                       │                     │
│   │ 100页文档 → 分成 200 个小块            │                     │
│   │ 每块约 500-1000 个字                   │                     │
│   │                                       │                     │
│   │ 块1: "第一章 公司简介 本公司成立于..."  │                     │
│   │ 块2: "1.2 公司愿景 我们致力于..."      │                     │
│   │ 块3: "第二章 员工守则 所有员工应..."    │                     │
│   │ ...                                   │                     │
│   └───────────────────────────────────────┘                     │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 3: 每块文本转成向量               │                     │
│   │                                       │                     │
│   │ 块1 ──Embedding模型──▶ 向量1           │                     │
│   │ 块2 ──Embedding模型──▶ 向量2           │                     │
│   │ 块3 ──Embedding模型──▶ 向量3           │                     │
│   │ ...                                   │                     │
│   │                                       │                     │
│   │ 200 个文本块 → 200 个向量              │                     │
│   └───────────────────────────────────────┘                     │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 4: 存入向量数据库                 │                     │
│   │                                       │                     │
│   │ ⚠️ 关键：200 个块 = 200 条记录！        │                     │
│   │                                       │                     │
│   │ 每条记录包含：                         │                     │
│   │ - 1 个原始文本（用于返回给用户看）      │                     │
│   │ - 1 个向量（用于相似度搜索）           │                     │
│   │ - 1 个标签（用于区分不同知识库）        │                     │
│   │                                       │                     │
│   │ 数据库表结构示意：                      │                     │
│   │ ┌────┬──────────────┬─────────────┬───────┐│                │
│   │ │ id │   content    │  embedding  │rag_tag││                │
│   │ ├────┼──────────────┼─────────────┼───────┤│                │
│   │ │  1 │ "公司简介..."│[0.12,-0.34]│员工手册││                │
│   │ │  2 │ "公司愿景..."│[0.23,-0.45]│员工手册││                │
│   │ │  3 │ "员工守则..."│[0.34,-0.56]│员工手册││                │
│   │ │... │ ...          │ ...         │ ...   ││                │
│   │ │200 │ "常见问题..."│[0.67,-0.89]│员工手册││                │
│   │ └────┴──────────────┴─────────────┴───────┘│                │
│   │                                       │                     │
│   │ 共插入 200 条记录，每条记录 1 个向量    │                     │
│   └───────────────────────────────────────┘                     │
│           │                                                     │
│           ▼                                                     │
│   ✅ 存储完成！文档已变成可搜索的知识库                           │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**简化版流程**：

```
原始文档 ──▶ 读取文本 ──▶ 分割成块 ──▶ 每块转向量 ──▶ 存入数据库
   │           │           │            │              │
  PDF        提取文字    切成小段     Embedding      pgvector
```

---

### 如何从向量数据库检索？（检索流程）

当用户提问时，系统会这样查找相关内容：

```
┌─────────────────────────────────────────────────────────────────┐
│                    检索完整流程（4 个步骤）                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   👤 用户提问                                                    │
│   "公司的年假政策是什么？"                                        │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 1: 问题转向量                     │                     │
│   │                                       │                     │
│   │ "公司的年假政策是什么？"                │                     │
│   │      ↓ Embedding 模型                  │                     │
│   │ 问题向量: [0.23, -0.45, 0.67, ...]     │                     │
│   └───────────────────────────────────────┘                     │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 2: 向量相似度搜索                 │                     │
│   │                                       │                     │
│   │ 把问题向量与数据库中每个文档块的向量比较  │                     │
│   │ 计算距离（距离越小 = 越相似）           │                     │
│   │                                       │                     │
│   │  块1 "公司简介..."      距离: 1.52     │                     │
│   │  块2 "员工年假规定..."  距离: 0.12 ✓   │                     │
│   │  块3 "请假流程说明..."  距离: 0.25 ✓   │                     │
│   │  块4 "财务报销流程..."  距离: 1.38     │                     │
│   │  ...                                  │                     │
│   └───────────────────────────────────────┘                     │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 3: 取出最相似的 Top N 条          │                     │
│   │                                       │                     │
│   │ 按距离排序，取前 3-5 条                │                     │
│   │                                       │                     │
│   │ Top 1: "员工入职满一年可享受5天年假..."│                     │
│   │ Top 2: "年假需提前3天申请..."          │                     │
│   │ Top 3: "未休年假可折算工资..."         │                     │
│   └───────────────────────────────────────┘                     │
│           │                                                     │
│           ▼                                                     │
│   ┌───────────────────────────────────────┐                     │
│   │ Step 4: 返回给后续流程                 │                     │
│   │                                       │                     │
│   │ 这些文本块会被组装成 Prompt            │                     │
│   │ 发送给 LLM 生成最终回答                │                     │
│   └───────────────────────────────────────┘                     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**对应的 SQL（简化版）**：

```sql
-- Step 2-3: 向量搜索
SELECT content 
FROM documents
WHERE rag_tag = '员工手册'                           -- 指定知识库
ORDER BY embedding <=> '[0.23, -0.45, 0.67, ...]'   -- 按相似度排序
LIMIT 3;                                            -- 取前3条
```

---

### rag_tag 是什么？为什么需要它？

你可能注意到了 SQL 里有个 `WHERE rag_tag = '员工手册'`，这个 **rag_tag** 是什么？

**简单说**：`rag_tag` 是知识库的**分类标签**，用来区分不同来源的文档。

#### 场景：你上传了多份文档

```
你的知识库内容：
├── 员工手册.pdf      → rag_tag = '员工手册'  (100 条记录)
├── 产品说明书.pdf    → rag_tag = '产品文档'  (50 条记录)  
├── 技术架构.md       → rag_tag = '技术文档'  (30 条记录)
└── 财务制度.pdf      → rag_tag = '财务制度'  (80 条记录)

共 260 条记录，都存在同一张表里
```

#### 没有 rag_tag 的问题

```sql
-- 用户问："年假政策是什么？"
-- 会在所有 260 条记录中搜索
SELECT content FROM documents
ORDER BY embedding <=> 问题向量
LIMIT 3;

-- 可能返回：
-- 1. "产品保修政策..."     ← ❌ 不相关！
-- 2. "员工年假规定..."     ← ✅ 相关
-- 3. "服务器技术规格..."   ← ❌ 不相关！
```

**问题**：搜索范围太大，结果不精准。

#### 有 rag_tag 的好处

```sql
-- 用户选择知识库 "员工手册" 后提问
SELECT content FROM documents
WHERE rag_tag = '员工手册'           -- 只在这 100 条中搜索
ORDER BY embedding <=> 问题向量
LIMIT 3;

-- 只返回员工手册相关的内容 ✅
```

#### 在你的项目中

```
┌──────────────────────────────────────────────────────────────┐
│                      AI 聊天界面                              │
├──────────────────────────────────────────────────────────────┤
│                                                              │
│  选择知识库：[员工手册 ▼]    ← 这里选择的就是 rag_tag        │
│                                                              │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ 💬 你：公司的年假政策是什么？                          │  │
│  │                                                        │  │
│  │ 🤖 AI：根据员工手册，员工入职满一年后可享受...         │  │
│  └────────────────────────────────────────────────────────┘  │
│                                                              │
└──────────────────────────────────────────────────────────────┘
```

#### 一句话总结

| 概念 | 作用 | 类比 |
|------|------|------|
| **rag_tag** | 区分不同知识库，让搜索更精准 | 图书馆的"书架分类" |

> 💡 **类比**：就像在图书馆找书，你要找技术书籍就去技术书架，不用在整个图书馆里找。

### 存储 vs 检索 对比

| 阶段 | 时机 | 频率 | 主要操作 |
|------|------|------|----------|
| **存储** | 上传文档时 | 一次性 | 分块 → 转向量 → 写入数据库 |
| **检索** | 用户提问时 | 每次提问 | 问题转向量 → 相似度搜索 → 返回结果 |

> 💡 **关键理解**：存储时把文档"打碎"成小块并转成向量；检索时用问题向量去"找"最相似的文档块。

---

## 🔍 第四章：RAG（检索增强生成）

### 什么是 RAG？

**RAG (Retrieval-Augmented Generation，检索增强生成)** 是一种让 LLM 能够访问**外部知识**的技术。

```
传统 LLM：
用户提问 → LLM（只能用训练时的知识）→ 回答（可能过时或不准确）

RAG 增强：
用户提问 → 检索相关文档 → LLM + 检索结果 → 回答（基于最新/私有数据）
```

### RAG 工作流程

```
┌─────────────────────────────────────────────────────────────┐
│                        RAG 完整流程                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  【准备阶段：建立知识库】                                     │
│                                                             │
│    公司文档/网页/PDF                                         │
│          ↓ 分割成小块                                        │
│    文本块 (Chunks)                                          │
│          ↓ Embedding 模型                                   │
│    向量                                                     │
│          ↓ 存储                                             │
│    向量数据库 (pgvector)                                     │
│                                                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  【查询阶段：回答问题】                                       │
│                                                             │
│    用户问题: "公司年假政策是什么？"                           │
│          ↓ Embedding                                        │
│    问题向量                                                  │
│          ↓ 相似度搜索                                        │
│    从向量数据库检索最相关的文档块                              │
│          ↓ 组合                                              │
│    Prompt = 问题 + 检索到的上下文                             │
│          ↓ 发送给 LLM                                        │
│    LLM 生成回答（基于检索到的内容）                           │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### RAG 的价值

| 问题 | RAG 如何解决 |
|------|-------------|
| LLM 知识过时 | 随时更新知识库，获取最新信息 |
| 无法访问私有数据 | 将公司文档导入知识库 |
| 回答不准确（幻觉） | 基于检索结果回答，更可靠 |
| 无法引用来源 | 可以返回答案来源的文档 |

### RAG vs 微调

| 方案 | 原理 | 优点 | 缺点 |
|------|------|------|------|
| **RAG** | 检索外部知识 | 灵活，可随时更新 | 依赖检索质量 |
| **微调** | 重新训练模型 | 知识内化 | 成本高，更新慢 |

> 💡 **实际应用**：大多数企业知识库场景用 RAG，因为更新方便、成本更低。

---

## 🦙 第五章：Ollama 本地大模型

### 什么是 Ollama？

**Ollama** 是一个让你在**本地电脑**上运行大语言模型的工具。

```
┌─────────────────────────────────────────────────────────────┐
│                          你的电脑                            │
│                                                             │
│   ┌─────────────────────────────────────────────────────┐   │
│   │                     Ollama                           │   │
│   │                                                     │   │
│   │   已下载的模型：                                     │   │
│   │   - qwen2.5:7b (对话模型)                           │   │
│   │   - nomic-embed-text (Embedding 模型)               │   │
│   │                                                     │   │
│   │   API 服务: http://localhost:11434                  │   │
│   │                                                     │   │
│   └─────────────────────────────────────────────────────┘   │
│                                                             │
│   你的应用 ──── HTTP 请求 ────▶ Ollama API                  │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 为什么使用 Ollama？

| 优势 | 说明 |
|------|------|
| **隐私安全** | 数据不出本地，适合敏感信息 |
| **无 API 费用** | 不需要按调用次数付费 |
| **离线可用** | 无网络也能使用 |
| **简单易用** | 一条命令下载和运行模型 |

### 常用命令

```bash
# 下载模型
ollama pull qwen2.5:7b

# 运行模型（交互式对话）
ollama run qwen2.5:7b

# 查看已下载的模型
ollama list

# 删除模型
ollama rm qwen2.5:7b

# 查看模型信息
ollama show qwen2.5:7b
```

### 模型选择指南

| 你的需求 | 推荐模型 | 内存要求 |
|----------|----------|----------|
| 快速测试 | qwen2.5:0.5b | 2GB |
| 日常对话 | qwen2.5:1.5b | 4GB |
| 高质量输出 | qwen2.5:7b | 8GB |
| 复杂推理 | deepseek-r1:7b | 8GB |
| 文本向量化 | nomic-embed-text | 2GB |

### API 调用示例

```bash
# 对话接口
curl http://localhost:11434/api/generate -d '{
  "model": "qwen2.5:7b",
  "prompt": "什么是 RAG？",
  "stream": false
}'

# Embedding 接口
curl http://localhost:11434/api/embeddings -d '{
  "model": "nomic-embed-text",
  "prompt": "这是一段测试文本"
}'
```

---

## 🔗 第六章：整合理解

### 本项目的技术栈

```
┌─────────────────────────────────────────────────────────────┐
│                  ai-rag-knowledge-study                     │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  用户界面 (前端)                                             │
│       ↓ HTTPS                                               │
│  Nginx (反向代理)                                            │
│       ↓                                                     │
│  Spring Boot 应用 (后端)                                     │
│       ↓                                                     │
│  ┌─────────────────────────────────────────────────────┐    │
│  │                 Spring AI 框架                       │    │
│  │                                                     │    │
│  │   ┌───────────┐     ┌───────────┐                   │    │
│  │   │  Ollama   │     │ OpenAI    │                   │    │
│  │   │  (本地)   │     │ (云端)    │                   │    │
│  │   └─────┬─────┘     └─────┬─────┘                   │    │
│  │         │                 │                         │    │
│  │         └────────┬────────┘                         │    │
│  │                  ↓                                  │    │
│  │         统一的 ChatClient 接口                       │    │
│  │                                                     │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐    │
│  │              PostgreSQL + pgvector                   │    │
│  │                                                     │    │
│  │   存储文档内容 + 向量，支持语义搜索                    │    │
│  │                                                     │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
│  Redis (缓存配置和会话)                                      │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 一次 RAG 对话的完整流程

```
1. 用户输入: "公司的年假制度是什么？"
        ↓
2. 后端调用 Embedding 模型（Ollama）
        ↓
3. 得到问题向量: [0.12, -0.34, ...]
        ↓
4. 在 pgvector 中搜索相似文档
        ↓
5. 找到相关文档块:
   - "员工入职满一年可享受 5 天年假..."
   - "年假需提前 3 天申请..."
        ↓
6. 构建 Prompt:
   "根据以下内容回答问题：
    [检索到的文档]
    问题：公司的年假制度是什么？"
        ↓
7. 调用 LLM（Ollama 或 OpenAI）
        ↓
8. 返回答案: "根据公司规定，员工入职满一年后..."
```

---

## 📚 术语表

| 术语 | 英文 | 解释 |
|------|------|------|
| 大语言模型 | LLM (Large Language Model) | 能理解和生成文本的 AI 模型 |
| 向量 | Vector | 一组数字，表示文本的语义特征 |
| 嵌入 | Embedding | 将文本转换为向量的过程/结果 |
| 向量数据库 | Vector Database | 专门存储和搜索向量的数据库 |
| 语义搜索 | Semantic Search | 按含义而非关键词搜索 |
| RAG | Retrieval-Augmented Generation | 检索增强生成，让 LLM 使用外部知识 |
| 幻觉 | Hallucination | AI 生成看似合理但错误的内容 |
| Token | Token | 文本的最小单位（约 0.5-1 个汉字） |
| Prompt | Prompt | 发给 AI 的输入/提示词 |

---

## 🎯 下一步学习建议

1. **动手实践**：完成 Docker 部署，实际运行本项目
2. **尝试对话**：在 AI 聊天界面与不同模型对话
3. **上传文档**：导入自己的文档，体验 RAG 效果
4. **阅读代码**：查看项目源码，理解实现细节

> 💡 **记住**：理论知识 + 动手实践 = 真正掌握

---

## 📖 推荐资源

- [Ollama 官网](https://ollama.ai/) - 本地大模型工具
- [pgvector 文档](https://github.com/pgvector/pgvector) - PostgreSQL 向量扩展
- [Spring AI 文档](https://docs.spring.io/spring-ai/reference/) - Java AI 框架
- [LangChain 教程](https://python.langchain.com/) - Python AI 应用框架

---

> **恭喜！** 🎉 你已经掌握了 AI 应用开发的核心概念。接下来就是动手实践了！

---

## 📚 文档导航

| 上一篇 | 下一篇 |
|--------|--------|
| [02-Docker 基础概念](./02-Docker基础概念.md) | [04-中间件部署](./04-中间件部署.md) |

[返回目录](./README.md)
